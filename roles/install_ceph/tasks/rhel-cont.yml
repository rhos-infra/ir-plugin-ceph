- name: setup rhceph-3.0.repo
  template: src=./templates/rhceph-3.0.repo.j2 dest=/etc/yum.repos.d/rhceph-3.0.repo

- name: check for subscription
  command: subscription-manager identity
  become: yes
  ignore_errors: yes
  register: cdn_status

- name: Register as user (subscr_user) with password (subscr_passwd) and auto-subscribe to available content if needed
  redhat_subscription:
     server_hostname: "{{subscr_server}}" 
     state: present
     username: "{{ subscr_user}}"
     password: "{{ subscr_password }}"
     autosubscribe: true
     server_insecure: yes
  when: cdn_status|failed
  retries: 10
  delay: 1
  ignore_errors: yes
  
- name: Install ceph-ansible
  yum: name=ceph-ansible state=present


- name: ignore the SSH authenticity checking made by Ansible
  lineinfile: dest=/usr/share/ceph-ansible/ansible.cfg line="host_key_checking = False"  insertafter=EOF state=present

- name: Copy all.yml.sample to all.yml
  copy: remote_src=True src=/usr/share/ceph-ansible/group_vars/all.yml.sample dest=/usr/share/ceph-ansible/group_vars/all.yml
- name: Configure package origin
  lineinfile: dest=/usr/share/ceph-ansible/group_vars/all.yml line="ceph_origin{{":"}} 'upstream'" insertafter=EOF state=present
- name: Configure all.yml
  blockinfile:
    path: /usr/share/ceph-ansible/group_vars/all.yml
    block: |
      ceph_origin: 'upstream'
      ceph_stable: true
      ceph_docker_image: rhceph
      ceph_docker_image_tag: 2.3
      journal_size: 100
      docker: true
      mon_containerized_deployment: ‘true’
      ceph_docker_registry: rhceph
      public_network: "{{ ansible_default_ipv4.address}}/{{ ansible_default_ipv4.netmask | ipaddr('prefix') }}"
      ceph_mon_docker_interface: "{{ ansible_default_ipv4.interface}}" 
      ceph_mon_docker_subnet: "{{ ansible_default_ipv4.address}}/{{ ansible_default_ipv4.netmask | ipaddr('prefix') }}"
      monitor_interface: "{{ ansible_default_ipv4.interface}}"

- name: Copy rgws.yml.sample to rgws.yml
  copy: remote_src=True src=/usr/share/ceph-ansible/group_vars/rgws.yml.sample dest=/usr/share/ceph-ansible/group_vars/rgws.yml
    
- name: Configure rgws.yml additions for docker
  blockinfile:
    path: /usr/share/ceph-ansible/group_vars/rgws.yml
    block: |
      rgw_containerized_deployment: true


- name: Copy osds.yml.sample to osds.yml
  copy: remote_src=True src=/usr/share/ceph-ansible/group_vars/osds.yml.sample dest=/usr/share/ceph-ansible/group_vars/osds.yml

- name: Configure osds.yml
  blockinfile:
    path: /usr/share/ceph-ansible/group_vars/osds.yml
    block: |
      devices:
        - /dev/vdb
      journal_collocation: true 
      osd_containerized_deployment: 'true'
      ceph_osd_docker_devices:
        - /dev/vdb 
      ceph_osd_docker_prepare_env: -e CLUSTER={{ '"{{' }} cluster {{ '}}"' }} -e OSD_JOURNAL_SIZE={{ '"{{' }} journal_size {{ '}}"' }} -e OSD_FORCE_ZAP=1 -e OSD_FILESTORE=1
      ceph_osd_docker_extra_env: -e CLUSTER={{ '"{{' }} cluster {{ '}}"' }} -e CEPH_DAEMON=OSD_CEPH_DISK_ACTIVATE -e OSD_JOURNAL_SIZE={{ '"{{' }} journal_size {{ '}}"' }} -e OSD_FILESTORE=1

#      ceph_osd_docker_devices: {{ '"{{' }} devices {{ '}}"' }}
#      ceph_osd_docker_prepare_env: -e CLUSTER={{ '{{' }} cluster {{ '}}' }} -e OSD_JOURNAL_SIZE={{ '{{' }} journal_size {{ '}}' }} -e OSD_FORCE_ZAP=1"

  
- name: Copy site-docker.yml.sample to site.yml
  copy: remote_src=True src=/usr/share/ceph-ansible/site-docker.yml.sample dest=/usr/share/ceph-ansible/site.yml

- name: Create and configure hosts file
  blockinfile:
    path: /usr/share/ceph-ansible/hosts
    create: yes
    block: |
      [clients]
      localhost ansible_connection=local
      
      [mons]
      localhost ansible_connection=local
      
      [osds]
      localhost ansible_connection=local
      
      [mdss]
      localhost ansible_connection=local
      
      [restapis]
      localhost ansible_connection=local

- name: install python-netaddr required to resolve ansible_default_ipv4.address
  yum: name=python-netaddr state=present

- name: Install ceph
  shell: ansible-playbook -vv -i hosts site.yml
  args:
     chdir: /usr/share/ceph-ansible

- name: Workaround. Fix ceph cluster health by reducing the number of replicas in each pool
  shell: "{{ item }}"
  with_items:
    - "ceph osd pool set cephfs_data size 1"
    - "ceph osd pool set cephfs_metadata size 1"

- name: Ceph health
  shell: ceph -s
  register: command_result
  failed_when: "'HEALTH_OK' not in command_result.stdout"

